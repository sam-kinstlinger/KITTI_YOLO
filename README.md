# Object_Tracking_KITTI
This project retrains a YOLOv8 model using the KITTI dataset for object detection and integrates an object tracking system to track vehicles in 2D images. The KITTI dataset, a standard benchmark for autonomous driving research, includes annotations for objects like cars, pedestrians, and cyclists. The project fine-tunes YOLOv8 to improve both detection and tracking performance, achieving a Multi-Object Tracking Accuracy (MOTA) of 0.71 at an IoU threshold of 0.5. The workflow involves preparing the dataset, converting annotations to YOLO format, splitting the data, fine-tuning YOLO, and implementing DeepSORT for vehicle tracking across video frames. Results are visualized in annotated images and a tracking video.

**Files**
- Split_Dataset.py: Splits the KITTI dataset into training and testing subsets.
- Convert_Labels.py: Converts KITTI annotations into YOLO-compatible format.
- YOLOv8_KITTI.py: Tests pre-trained YOLOv8 on the KITTI dataset, fine-tunes the model using KITTI training data, evaluates performance, and displays results.
- DeepSORT_Vehicle_Tracking.py: Implements object tracking using the retrained YOLOv8 for detection and DeepSORT for tracking vehicles across frames. It processes input images, detects and tracks objects, and saves annotated images and a video of the tracked objects.
- tracking_output.mp4: A file containing a video showing tracked objects over time for a single sequence, generated by this project.
- data.yml: The dataset configuration file specifying paths, the number of classes, and class names.

**Steps**
- Install necessary libraries
- Download KITTI dataset image sequences
- Run Split_Dataset.py
- Run Convert_Labels.py
- Run YOLOv8_KITTI.py
  - Results will be saved in the runs/predict directory for visualization
  - The fine-tuned model and weights will be saved in the runs/train/weights directory
- Run DeepSORT_Vehicle_Tracking.py
  - Annotated images with bounding boxes, object IDs, and velocity information will be saved in /dataset/output.
  - A video showing tracked objects over time for each sequence will be saved in /tracking_output  
